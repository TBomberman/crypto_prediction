optimizers = {
    0: 'sgd',
    1: 'rmsprop',
    2: 'adagrad',
    3: 'adadelta',
    4: 'adam',
    5: 'adamax',
    6: 'nadam'
}

activation_functions = {
    0: 'elu',
    1: 'selu',
    2: 'sigmoid',
    3: 'linear',
    4: 'softplus',
    5: 'softmax',
    6: 'tanh',
    7: 'hard_sigmoid',
    8: 'relu',
    9: 'softsign'
}
